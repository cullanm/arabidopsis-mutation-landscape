{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab6a8ee-f35f-4d3f-9fd9-2baf7652b143",
   "metadata": {},
   "source": [
    "# DEPRECATED\n",
    "\n",
    "use the script generate_duplex_blacklists.py now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random as rd\n",
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "from matplotlib.patches import Rectangle\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/../python_scripts')\n",
    "import gtools\n",
    "import matplotlib.patches as mpatches\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_file = '../data/ref/ref.fa.fai'\n",
    "genome_fasta = '../data/ref/ref.fa'\n",
    "sample_names = 'S3-1 S4-1 M1-1'.split()\n",
    "coverage_files = [f'../data/coverage/total/justin_{sample}.bg' for sample in sample_names] # generated from bedtools genomecov -bg\n",
    "# samples = itertools.chain.from_iterable([[x + '_1', x + '_2', x + '_3'] for x in 'ku80 parp2 rad5a chr8 msh2 rad7a'.split()])\n",
    "# naive_files = [f'../data/variant/big_Col-0_{s}_naive.tsv' for s in range(1, 9)] + [f'../data/variant/big_{s}_naive.tsv' for s in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load size of chromosomes from a fasta index\n",
    "chrom_sizes = dict()\n",
    "with open(genome_file, 'r') as f:\n",
    "    for l in f:\n",
    "        chrom_sizes[l.split()[0]] = int(l.split()[1])\n",
    "# chrom_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a file with columns: chrom, pos, coverage into numpy arrays\n",
    "coverage = dict()\n",
    "for chrom in chrom_sizes:\n",
    "    coverage[chrom] = np.zeros(chrom_sizes[chrom], dtype='i')\n",
    "for file in coverage_files:\n",
    "    with open(file, 'r') as f:\n",
    "        for l in tqdm(f):\n",
    "            fields = l.split()\n",
    "            if 'e' in fields[3]: # if number is in scientific notation, python needs to convert to int using a float intermediate\n",
    "                c = int(float(fields[3]))\n",
    "            else:\n",
    "                c = int(fields[3])\n",
    "            coverage[fields[0]][int(fields[1]):int(fields[2])] += c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom in chrom_sizes:\n",
    "    np.save(f'tmp/blacklist_coverage_sum_{chrom}.npy', coverage[chrom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = dict()\n",
    "for chrom in chrom_sizes:\n",
    "    coverage[chrom] = np.load(f'tmp/blacklist_coverage_sum_{chrom}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage['chr10'][100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.count_nonzero(coverage['chr2'] < 0) == 0 # no negative coverages present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Plot a histogram of read coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample 10M positions of the genome and get their coverage\n",
    "sample_size = 10000000\n",
    "chroms = rd.choices(list(chrom_sizes.keys()), k=sample_size, weights=chrom_sizes.values()) # select chroms to sample from, weighted by size\n",
    "bootstrap = []\n",
    "for chrom in chroms: # for each chrom selected, get the coverage at a random position\n",
    "    bootstrap.append(coverage[chrom][rd.randrange(chrom_sizes[chrom])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "maxcov = 1000\n",
    "hist = ax.hist(bootstrap, log=False, bins=range(maxcov))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Make an array of the coverage percentile by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentile value of each coverage (e.g. percentile[10] == 0.01 means 1% of positions in the genome have less than 10 coverage)\n",
    "percentile = np.zeros(maxcov)\n",
    "for i in tqdm(range(len(percentile))): # for each coverage amount\n",
    "    lower_total = 0\n",
    "    for j in range(i): # sum the occurences of lesser coverages\n",
    "        lower_total += hist[0][j]\n",
    "    percentile[i] = lower_total / len(bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile[maxcov - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each coverage value in the genome into a percentile\n",
    "cov_percentile = dict() # cov_percentile[chrom][pos] = percent of genome with lesser coverage\n",
    "for chrom in tqdm(chrom_sizes):\n",
    "    # apply function to coverage array to convert coverage to percentile\n",
    "    cov_percentile[chrom] = np.vectorize(lambda x: percentile[x] if x < len(percentile) else percentile[-1])(coverage[chrom])\n",
    "    del coverage[chrom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_percentile['chr1'][10000:10010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Make an array of duplicated regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of mismatches required for a 120bp kmer starting at a position to have a duplicate\n",
    "duplicate_dist = dict() # duplicate_dist[chrom][pos] = number of bases which must be changed before the kmer has a duplicate, or 10 if no duplicate was found\n",
    "for chrom in chrom_sizes:\n",
    "    duplicate_dist[chrom] = np.full(chrom_sizes[chrom], 10, dtype=np.byte)\n",
    "\n",
    "for i in range(0, -1, -1):\n",
    "    with open(f'../data/ref/genmap_output_w22/120_{i}.bedgraph', 'r') as f:\n",
    "        for l in tqdm(f):\n",
    "            fields = l.split()\n",
    "            # set values within the bedgraph interval. If occurences is 1 (unique) keep value the same, else set value to i\n",
    "            duplicate_dist[fields[0]][int(fields[1]):int(fields[2])] = duplicate_dist[fields[0]][int(fields[1]):int(fields[2])] * (fields[3] == '1') + i * (fields[3]  != '1')\n",
    "\n",
    "for i in range(4):\n",
    "    print(f'{sum([np.count_nonzero(duplicate_dist[chrom] == i) for chrom in chrom_sizes]) / sum(chrom_sizes.values()) * 100}% of the genome has a (120, {i}) duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_dist['Chr1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make an array of polynucleotide repeat length starting/ending at each position\n",
    "\n",
    "Most of the time, false positives generated by polynuc repeats are indels which appear at the start position of the repeat (as bowtie2 always chooses the start rather than the end if it captures the whole repeat in the read). However, mismatches can also result in rarer cases, sometimes because the repeat is near a read end or because two different repeats are adjacent. Mismatches and some indels can be placed 1bp upstream the start or 1bp downstream the end position of the repeat, so those positions are also counted. Poly C and poly G repeats don't seem to cause errors for whatever reason (less likely to slip?) and aren't counted.\n",
    "\n",
    "e.g.\n",
    "```\n",
    "sequence: ACTGAAAAAAAAGTCGAGAGAGAGACTGC\n",
    "array:    00088000000880554000000455000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = gtools.load_genome(genome_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make zero arrays for poly \n",
    "poly_at_len = dict() # poly_at_len[chrom][pos] = length of longest poly-A or poly-T which starts or ends at the position (or the position is 1bp outside of)\n",
    "poly_rep_len = dict() # poly_rep_len[chrom][pos] = length (in number of repeats) of longest di/tri-nuc repeat which starts or ends at the position (or the position is 1bp outside of)\n",
    "for chrom in chrom_sizes:\n",
    "    poly_at_len[chrom] = np.zeros(chrom_sizes[chrom], dtype='b')\n",
    "    poly_rep_len[chrom] = np.zeros(chrom_sizes[chrom], dtype='b')\n",
    "\n",
    "# get regex iterables for each possible nucleotide repeat\n",
    "match_iters = defaultdict(lambda: [])\n",
    "for chrom in chrom_sizes:\n",
    "    match_iters[chrom].append((1, re.finditer('AAAA+', genome[chrom]))) # poly A, the \"1\" here is the length of repeat, will be \"2\" for di and \"3\" for tri\n",
    "    match_iters[chrom].append((1, re.finditer('TTTT+', genome[chrom]))) # poly T\n",
    "    for x in 'ACGT':\n",
    "        for y in 'ACGT':\n",
    "            if x != y: # two nucleotides must be different to be a dinucleotide repeat\n",
    "                match_iters[chrom].append((2, re.finditer('(' + x + y + '){3,}', genome[chrom]))) # dinucleotide repeats\n",
    "            for z in 'ACGT':\n",
    "                if x != y or x != z or y != z: # at least one pair of nucleotides must be different to be a trinucleotide repeat\n",
    "                    match_iters[chrom].append((3, re.finditer('(' + x + y + z + '){3,}', genome[chrom]))) # trinucleotide repeats\n",
    "    \n",
    "# iterate through each regex iterable and add the length of the repeat to the array\n",
    "for chrom in match_iters:\n",
    "    for replen, it in tqdm(match_iters[chrom]): # for each regex search (e.g. CT repeats)\n",
    "        for match in it:\n",
    "            start = match.span()[0]\n",
    "            end = match.span()[1]\n",
    "            poly_len = (end - start) // replen\n",
    "            if replen == 1:\n",
    "                poly_at_len[chrom][start - 1] = max(poly_at_len[chrom][start - 1], poly_len)\n",
    "                poly_at_len[chrom][start] = max(poly_at_len[chrom][start], poly_len)\n",
    "                poly_at_len[chrom][end - 1] = max(poly_at_len[chrom][end - 1], poly_len)\n",
    "                if end != chrom_sizes[chrom]: # this happens if the chrom ends with a poly repeat\n",
    "                    poly_at_len[chrom][end] = max(poly_at_len[chrom][end], poly_len)\n",
    "            else:\n",
    "                poly_rep_len[chrom][start - 1] = max(poly_rep_len[chrom][start - 1], poly_len)\n",
    "                poly_rep_len[chrom][start] = max(poly_rep_len[chrom][start], poly_len)\n",
    "                poly_rep_len[chrom][end - 1] = max(poly_rep_len[chrom][end - 1], poly_len)\n",
    "                if end != chrom_sizes[chrom]:\n",
    "                    poly_rep_len[chrom][end] = max(poly_rep_len[chrom][end], poly_len)\n",
    "\n",
    "for i in range(4, 10):\n",
    "    print(f'blacklisted {sum(np.count_nonzero(poly_at_len[chrom] == i) for chrom in chrom_sizes) / sum(chrom_sizes.values()) * 100}% for length {i} A/T nucleotide repeats')\n",
    "for i in range(3, 10):\n",
    "    print(f'blacklisted {sum(np.count_nonzero(poly_rep_len[chrom] == i) for chrom in chrom_sizes) / sum(chrom_sizes.values()) * 100}% for length {i} di/tri nucleotide repeats')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualize blacklisted regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 100000\n",
    "fig, axs = plt.subplots(sum(['chr' in chrom for chrom in chrom_sizes]) + 1, sharex=True, sharey=True, figsize=(14, 6))\n",
    "for i, chrom in tqdm(enumerate(chrom_sizes)):\n",
    "    binned_cov = []\n",
    "    binned_cov_per = []\n",
    "    binned_dup_dist = []\n",
    "    binned_at_len = []\n",
    "    binned_rep_len = []\n",
    "    \n",
    "    # calculate the average coverage/blacklist for each bin\n",
    "    for j in range(0, chrom_sizes[chrom] + bin_size, bin_size):\n",
    "        # binned_cov.append(sum(coverage[chrom][j:j+bin_size]) / bin_size)\n",
    "        binned_cov_per.append(np.count_nonzero((cov_percentile[chrom][j:j+bin_size] < 0.007) | (cov_percentile[chrom][j:j+bin_size] > 0.993)) / bin_size)\n",
    "        binned_dup_dist.append(np.count_nonzero(duplicate_dist[chrom][j:j+bin_size] < 1) / bin_size)\n",
    "        binned_at_len.append(np.count_nonzero(poly_at_len[chrom][j:j+bin_size] > 5) / bin_size)\n",
    "        binned_rep_len.append(np.count_nonzero(poly_rep_len[chrom][j:j+bin_size] > 3) / bin_size)\n",
    "    \n",
    "    # make secondary axes to plot blacklists on\n",
    "    axs[i].plot(range(len(binned_cov_per)), binned_cov_per, color='tab:orange')\n",
    "    axs[i].plot(range(len(binned_dup_dist)), binned_dup_dist, color='tab:green')\n",
    "    axs[i].plot(range(len(binned_at_len)), binned_at_len, color='tab:red')\n",
    "    \n",
    "    axs[i].set_title(chrom, y=0.35)\n",
    "    \n",
    "    if 'chr' not in chrom:\n",
    "        break\n",
    "axs[0].set_ylim(0, 1)\n",
    "# manually make a legend\n",
    "# cov = mpatches.Patch(color='tab:blue', label='Coverage')\n",
    "dup = mpatches.Patch(color='tab:orange', label='Cov blacklist')\n",
    "unmap = mpatches.Patch(color='tab:green', label='Unmap blacklist')\n",
    "rep = mpatches.Patch(color='tab:red', label='Nuc repeat blacklist')\n",
    "fig.legend(handles=[dup, unmap, rep], bbox_to_anchor=(1.08, 0.89))\n",
    "\n",
    "fig.suptitle('Blacklist content of genome', y=0.96)\n",
    "fig.savefig('figs/blacklist_content_of_genome.svg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Output blacklists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom in duplicate_dist:\n",
    "    # np.save(f'../data/blacklist/w22/{chrom}_coverage_percentile.npy', cov_percentile[chrom])\n",
    "    np.save(f'../data/blacklist/w22/{chrom}_duplicate_distance.npy', duplicate_dist[chrom])\n",
    "    # np.save(f'../data/blacklist/w22/{chrom}_poly_at_length.npy', poly_at_len[chrom])\n",
    "    # np.save(f'../data/blacklist/w22/{chrom}_poly_repeat_length.npy', poly_rep_len[chrom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero((cov_percentile['chr1'] < 0.007)), chrom_sizes['chr1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
