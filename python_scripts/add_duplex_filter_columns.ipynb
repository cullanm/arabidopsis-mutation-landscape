{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gtools\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='''\n",
    "Adds columns to the duplex-seq variants generated by duplex_caller.py which are required for filtering with filter_duplex_variants.py.|n\n",
    "\n",
    "Requires the following as input:|n\n",
    "    - duplex variant tsv: generated by running duplex_caller.py on the sample to call variants within|n\n",
    "    - variant frequency tsv: generated by running dup_informed_caller.py --duplicate_support 2 on the same sample sample as the duplex variant tsv. This will be \n",
    "        used to calculate the fraction of molecules in the sample which support each variant|n\n",
    "    - control tsvs: generated by running dup_informed_caller.py --duplicate_support 2 --min_support 2 on different samples. This will be used to filter out any \n",
    "        variants which occur too frequently in these samples|n\n",
    "    - blacklists: generated by generate_duplex_blacklists.py|n\n",
    "\n",
    "Will add the following columns to the duplex variant tsv:|n\n",
    "    - high_sup: number of supporting bases with BQ>=30|n\n",
    "    - avg_mq: average MQ of supporting reads|n\n",
    "    - cov_per: coverage percentile of the variant site, uses blacklist (e.g. 0.02 means 2% of the genome has a lower read coverage than the variant position)|n\n",
    "    - dup_dist: minimum hamming distance between the fragment containing the variant and another genomic position, uses blacklist (e.g. 2 means there's another kmer \n",
    "    in the genome that's 2 edits away from the kmer starting at the fragment start (the value of \"k\" is defined when blacklists are generated and is not necessarily\n",
    "    the fragment length))|n\n",
    "    - poly_at: length of longest poly-A/T repeat ending at or 1bp away from the variant position, uses blacklist (e.g. 5 means the variant is at the end of a 5bp \n",
    "    poly-A or poly-T repeat)|n\n",
    "    - poly_rep: length of longest poly-di/trinucleotide repeat ending at or 1bp away from the variant position, uses blacklist (e.g. 4 means the variant is at the  \n",
    "    end of a length 3 dinucleotide or trinucleotide repeat (e.g. CCTCCTCCT))|n\n",
    "    - sample_sup: number of fragments in the sample which support the variant, uses the variant frequency tsv|n\n",
    "    - sample_cov: number of fragments in the sample which overlap the variant position, uses the variant frequency tsv|n\n",
    "    - control_sup: number of fragments in the control samples which support the variant, uses the control tsvs for this|n\n",
    "    ''', formatter_class=gtools.EscapeFormatter)\n",
    "parser.add_argument('-i', '--input', required=True, dest='duplex_tsv', metavar='TSV', type=str,\n",
    "                   help='generated by running duplex_caller.py on the sample to call variants within. Must be sorted by chrom-pos-ref-alt, \\\n",
    "                   which duplex_caller.py does by default.')\n",
    "parser.add_argument('-f', '--frequency', required=True, dest='frequency_tsv', metavar='TSV', type=str,\n",
    "                   help='generated by running dup_informed_caller.py --duplicate_support 2 on the same sample sample as --input. Must be \\\n",
    "                   sorted by chrom-pos-ref-alt, which dup_informed_caller.py does by default.')\n",
    "parser.add_argument('-c', '--controls', required=True, dest='control_tsvs', metavar='TSV', type=str, nargs='+',\n",
    "                   help='generated by running dup_informed_caller.py --duplicate_support 2 --min_support 2 on samples other than --input')\n",
    "parser.add_argument('-b', '--blacklists', required=True, dest='blacklist_prefix', metavar='PREFIX', type=str, \n",
    "                   help='prefix of the blacklist files, same as was passed to generate_duplex_blacklists --prefix. Will look for {prefix}{chrom}_{blacklist type}.npy, \\\n",
    "                   where blacklist type is coverage_percentile, duplicate_distance, poly_at_length, and poly_repeat_length.')\n",
    "parser.add_argument('-o', '--output', dest='output_tsv', metavar='TSV', type=str,\n",
    "                   help='output tsv. Will have the same variants as --input but with extra columns added (default: stdout)')\n",
    "\n",
    "if gtools.running_notebook(): # run this if in a jupyter notebook\n",
    "    print('Determined code is running in Jupyter')\n",
    "    if os.getcwd()[:8] != '/scratch': # switch to the scratch directory where all the data files are\n",
    "        os.chdir(f'/scratch/cam02551/{os.getcwd().split(\"/\")[-2]}')\n",
    "    args = parser.parse_args('-i data/variant/big_Col-0-1_duplex_strandsup.tsv -o tmp/test_add_duplex.tsv -f data/variant/big_Col-0-1_informed_freq.tsv -b data/blacklist/arabidopsis/duplex_blacklist_ -c data/variant/big_Col-0-2_informed_control.tsv data/variant/big_Col-0-3_informed_control.tsv'.split()) # used for testing\n",
    "else: # run this if in a terminal\n",
    "    args = parser.parse_args()\n",
    "\n",
    "if args.output_tsv is not None and '/' in args.output_tsv:\n",
    "    os.makedirs(os.path.dirname(args.output_tsv), exist_ok=True)\n",
    "sys.stderr.write('Running add_duplex_filter_columns.py with arguments:\\n' + '\\n'.join([f'{key}={val}' for key, val in vars(args).items()]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Load blacklists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all chromosomes in the input\n",
    "sys.stderr.write('finding all chromosomes in input tsv\\n')\n",
    "chroms = set()\n",
    "total_lines = 0\n",
    "with open(args.duplex_tsv, 'r') as f:\n",
    "    next(f) # skip header\n",
    "    for l in f:\n",
    "        chroms.add(l.split('\\t', 1)[0])\n",
    "        total_lines += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stderr.write('loading blacklists\\n')\n",
    "\n",
    "# all are indexed as bl[chrom][pos] = value\n",
    "bl_cov_per = dict() # coverage percentile\n",
    "bl_dup_dist = dict() # mismatches required to have a duplicate 120mer in the genome\n",
    "bl_poly_at = dict() # length of poly-A or poly-T starting or ending at position\n",
    "bl_poly_rep = dict() # length of di or trinucleotide repeat starting or ending at position\n",
    "for chrom in tqdm(chroms):\n",
    "    bl_cov_per[chrom] = np.load(f'{args.blacklist_prefix}{chrom}_coverage_percentile.npy')\n",
    "    bl_dup_dist[chrom] = np.load(f'{args.blacklist_prefix}{chrom}_duplicate_distance.npy')\n",
    "    bl_poly_at[chrom] = np.load(f'{args.blacklist_prefix}{chrom}_poly_at_length.npy')\n",
    "    bl_poly_rep[chrom] = np.load(f'{args.blacklist_prefix}{chrom}_poly_repeat_length.npy')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_var(line):\n",
    "    var = line[:-1].split('\\t')\n",
    "    var[1] = int(var[1]) # change position to an int\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_mut_info(call_file, freq_file, control_files, output_file):\n",
    "\n",
    "# open all files\n",
    "f_call = open(args.duplex_tsv, 'r')\n",
    "f_freq = open(args.frequency_tsv, 'r')\n",
    "f_conts = [open(f, 'r') for f in args.control_tsvs]\n",
    "f_out = open(args.output_tsv, 'w') if args.output_tsv is not None else sys.stdout\n",
    "\n",
    "# extract the header from all files\n",
    "try:\n",
    "    dcs = {x:i for i, x in enumerate(next(f_call)[:-1].split('\\t'))} # converts a column name to column index for duplex_caller tsv\n",
    "    ics = {x:i for i, x in enumerate(next(f_freq)[:-1].split('\\t'))} # converts a column name to column index for dup_informed_caller tsv\n",
    "    [next(f) for f in f_conts]\n",
    "    \n",
    "    # write the output header with extra columns\n",
    "    f_out.write('\\t'.join(list(dcs.keys()) + 'high_sup avg_mq cov_per dup_dist poly_at poly_rep sample_sup sample_cov control_sup'.split()) + '\\n')\n",
    "\n",
    "    # load the first freq and control variants\n",
    "    cur_freq = line_to_var(next(f_freq))\n",
    "    cur_conts = [line_to_var(next(f)) for f in f_conts]\n",
    "    \n",
    "except StopIteration as e:\n",
    "    sys.stderr.write(f'ERROR: one of the input tsvs is empty\\n')\n",
    "    sys.stderr.write(e)\n",
    "    exit()\n",
    "\n",
    "# for each variant in the call file, add extra information and output\n",
    "bar = tqdm(total=total_lines, miniters=10000, maxinterval=999)\n",
    "while True:\n",
    "    # get the next variant in the call file\n",
    "    try:\n",
    "        cur_var = line_to_var(next(f_call))\n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "    # calculate the number of supporting reads with a high BQ value (>=30)\n",
    "    if cur_var[dcs['ref']] == '*' or cur_var[dcs['alt']] == '*':\n",
    "        high_sup = int(cur_var[dcs['f_sup']]) + int(cur_var[dcs['r_sup']])\n",
    "    else:\n",
    "        high_sup = sum([(ord(bq) - 33) >= 30 for bq in cur_var[dcs['bq']]])\n",
    "\n",
    "    # calculate the average MQ of supporting reads\n",
    "    avg_mq = sum([ord(mq) - 33 for mq in cur_var[dcs['mq']]]) / len(cur_var[dcs['mq']])\n",
    "\n",
    "    # find the blacklist values\n",
    "    cov_per = bl_cov_per[cur_var[dcs['chrom']]][int(cur_var[dcs['pos']])]\n",
    "    dup_dist = bl_dup_dist[cur_var[dcs['chrom']]][int(cur_var[dcs['pos']])]\n",
    "    poly_at = bl_poly_at[cur_var[dcs['chrom']]][int(cur_var[dcs['pos']])]\n",
    "    poly_rep = bl_poly_rep[cur_var[dcs['chrom']]][int(cur_var[dcs['pos']])]\n",
    "\n",
    "    # read in variants from the frequency and control files until at or past the current variant\n",
    "    while cur_freq[:4] < cur_var[:4]:\n",
    "        try:\n",
    "            cur_freq = line_to_var(next(f_freq))\n",
    "        except StopIteration:\n",
    "            cur_freq = [chr(1000)]\n",
    "\n",
    "    for i in range(len(f_conts)):\n",
    "        while cur_conts[i][:4] < cur_var[:4]:\n",
    "            try:\n",
    "                cur_conts[i] = line_to_var(next(f_conts[i]))\n",
    "            except StopIteration:\n",
    "                cur_conts[i] = [chr(1000)]\n",
    "\n",
    "    # add the support and coverage of the variant within the sample\n",
    "    if cur_freq[:4] == cur_var[:4]:\n",
    "        sample_sup = int(cur_freq[ics['f_sup']]) + int(cur_freq[ics['r_sup']])\n",
    "        sample_cov = int(cur_freq[ics['f_cov']]) + int(cur_freq[ics['r_cov']])\n",
    "    else:\n",
    "        sample_sup = 0\n",
    "        sample_cov = 0\n",
    "\n",
    "    # add the support of the variant across all control samples\n",
    "    control_sup = 0\n",
    "    for i in range(len(f_conts)):\n",
    "        if cur_conts[i][:4] == cur_var[:4]:\n",
    "            control_sup += int(cur_conts[i][ics['f_sup']]) + int(cur_conts[i][ics['r_sup']])\n",
    "\n",
    "    cur_var += [high_sup, avg_mq, cov_per, dup_dist, poly_at, poly_rep, sample_sup, sample_cov, control_sup]\n",
    "\n",
    "    if True:\n",
    "        f_out.write('\\t'.join(map(str, cur_var)) + '\\n')\n",
    "\n",
    "    bar.update()\n",
    "\n",
    "f_call.close()\n",
    "f_freq.close()\n",
    "for f in f_conts:\n",
    "    f.close()\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stderr.write(f'completed add_duplex_filter_columns.py on {args.duplex_tsv}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
