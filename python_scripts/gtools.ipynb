{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from multiprocessing import Process\n",
    "import numpy as np\n",
    "import pysam\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_genome(file):\n",
    "    genome = dict()\n",
    "    with open(file, 'r') as f:\n",
    "        ls = f.read()\n",
    "        ls = ls.split('>')[1:]\n",
    "        for l in ls:\n",
    "            genome[l.split(None, 1)[0]] = l.split('\\n', 1)[1].replace('\\n', '')\n",
    "    return genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a VCF file as a pandas dataframe with format matching that of duplex_caller. \n",
    "# POS: changed to 0-based\n",
    "# REF & ALT: converts indels to asterisk format, and unpacks records containing multiple variants at the same position to separate rows\n",
    "# e.g. the variant Chr1 10 TA C,TCAA,T,TAG,TAAA,TAAAA will be converted to:\n",
    "#                  Chr1 9  T  C\n",
    "#                  Chr1 10 A     C\n",
    "#                  Chr1 11 *      AA\n",
    "#                  Chr1 10 A         *\n",
    "#                  Chr1 11 *             G\n",
    "#                  Chr1 11 *                 AA\n",
    "#                  Chr1 11 *                      AAA\n",
    "# \n",
    "# INFO: unpacked to separate columns for each info item in the header\n",
    "# FORMAT & SAMPLEs: each sample column is unpacked into a separate column for each format field in the header\n",
    "def load_vcf(file, descriptions=False, nrecords=None):\n",
    "    fin = open(file, 'r')\n",
    "    l = next(fin, None)\n",
    "    \n",
    "    infos = dict()\n",
    "    formats = dict()\n",
    "    while l is not None:\n",
    "        if l[0] == '#':\n",
    "            if l[1] != '#':\n",
    "                samples = l[1:].strip().split()[9:]\n",
    "            elif l[:6] == '##INFO':\n",
    "                infos[l.split('ID=')[1].split(',')[0]] = (l.split('Number=')[1].split(','), l.split('Description=\"')[1].split('\"')[0])\n",
    "            elif l[:8] == '##FORMAT':\n",
    "                formats[l.split('ID=')[1].split(',')[0]] = (l.split('Number=')[1].split(','), l.split('Description=\"')[1].split('\"')[0])\n",
    "        else:\n",
    "            break\n",
    "        l = next(fin, None)\n",
    "    \n",
    "    header = 'chrom pos id ref alt qual fil'.split() + list(infos.keys())\n",
    "    for sample in samples:\n",
    "        header += [f'{sample}_{form}' for form in formats]\n",
    "    \n",
    "    variants = []\n",
    "    records_read = 0\n",
    "    while l is not None:\n",
    "        var_base = {h:None for h in header}\n",
    "        raw = l.strip().split('\\t')\n",
    "        \n",
    "        # add the static fields\n",
    "        var_base['chrom'] = raw[0]\n",
    "        var_base['pos'] = raw[1]\n",
    "        var_base['id'] = raw[2]\n",
    "        var_base['ref'] = raw[3]\n",
    "        var_base['alt'] = raw[4]\n",
    "        var_base['qual'] = raw[5]\n",
    "        var_base['fil'] = raw[6]\n",
    "        \n",
    "        # add the INFO fields\n",
    "        for x in raw[7].split(';'):\n",
    "            x = x.split('=')\n",
    "            if len(x) == 1:\n",
    "                val = True\n",
    "            elif infos[x[0]] == 'A':\n",
    "                val = x[1].split(',')\n",
    "            else:\n",
    "                val = x[1]\n",
    "            var_base[x[0]] = val\n",
    "            \n",
    "        # add the FORMAT fields\n",
    "        forms = raw[8].split(':')\n",
    "        for sample_idx, sample_field in enumerate(raw[9:]):\n",
    "            for format_idx, value in enumerate(sample_field.split(':')):\n",
    "                var_base[f'{samples[sample_idx]}_{forms[format_idx]}'] = value\n",
    "        \n",
    "        start_pos = int(var_base['pos'])\n",
    "        ref = var_base['ref']\n",
    "        alts = var_base['alt'].split(',')\n",
    "        vars_to_add = []\n",
    "        for alt_idx, alt in enumerate(alts):\n",
    "            for i in range(min(len(ref), len(alt))): # iterate through the positions until we run out of bases in ref or alt\n",
    "                if ref[i] != alt[i]: # output all mismatches as snps\n",
    "                    v = var_base.copy()\n",
    "                    v['pos'] = start_pos - 1 + i\n",
    "                    v['ref'] = ref[i]\n",
    "                    v['alt'] = alt[i]\n",
    "                    for info in [x for x in infos if infos[x][0] == 'A']:\n",
    "                        v[info] = var_base[info][alt_idx]\n",
    "                    vars_to_add.append(v)\n",
    "            if len(ref) == len(alt): # if there's no indel here\n",
    "                pass\n",
    "            elif len(ref) > len(alt): # if a deletion, the starting bases will be lined up, so the extra bases at the end of ref are what's deleted\n",
    "                v = var_base.copy()\n",
    "                v['pos'] = start_pos - 1 + min(len(ref), len(alt))\n",
    "                v['ref'] = ref[len(alt):]\n",
    "                v['alt'] = '*'\n",
    "                for info in [x for x in infos if infos[x][0] == 'A']:\n",
    "                    v[info] = var_base[info][alt_idx]\n",
    "                vars_to_add.append(v)\n",
    "            else: # in an insertion, the extra bases at the end of alt are what's inserted\n",
    "                v = var_base.copy()\n",
    "                v['pos'] = start_pos - 1 + min(len(ref), len(alt))\n",
    "                v['ref'] = '*'\n",
    "                v['alt'] = alt[len(ref):]\n",
    "                for info in [x for x in infos if infos[x][0] == 'A']:\n",
    "                    v[info] = var_base[info][alt_idx]\n",
    "                vars_to_add.append(v)\n",
    "        vars_to_add.sort(key=lambda v: v['pos'])\n",
    "        variants += [list(v.values()) for v in vars_to_add]\n",
    "        \n",
    "        l = next(fin, None)\n",
    "        records_read += 1\n",
    "        if nrecords is not None and records_read == nrecords:\n",
    "            break\n",
    "    \n",
    "    fin.close()\n",
    "    \n",
    "    df = pd.DataFrame(variants, columns=header)\n",
    "    df.pos = pd.to_numeric(df.pos)\n",
    "    if descriptions:\n",
    "        return df, infos, formats\n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.getcwd() + '/../python_scripts') # this lets us import files in python_scripts (like gtools)\n",
    "# import gtools\n",
    "# if os.getcwd()[:8] != '/scratch': # switch to the scratch directory where all the data files are\n",
    "#     os.chdir(f'/scratch/cam02551/{os.getcwd().split(\"/\")[-2]}')\n",
    "    \n",
    "# df = load_vcf('data/variant/mutect/big_Col-0-1_filtered.vcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chrom_sizes(index):\n",
    "    chrom_sizes = dict()\n",
    "    with open(index, 'r') as f:\n",
    "        for l in f:\n",
    "            split = l[:-1].split('\\t')\n",
    "            chrom_sizes[split[0]] = int(split[1])\n",
    "    return chrom_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coverage_bedgraph(bg, index):\n",
    "    chrom_sizes = load_chrom_sizes(index)\n",
    "    coverage = {chrom:np.zeros(chrom_sizes[chrom], dtype='i') for chrom in chrom_sizes}\n",
    "    with open(bg, 'r') as f:\n",
    "        for l in f:\n",
    "            split = l[:-1].split('\\t')\n",
    "            coverage[split[0]][int(split[1]):int(split[2])] = int(float(split[3]))\n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_commands(commands):\n",
    "    for command in tqdm(commands):\n",
    "        # print('Running: ' + command)\n",
    "        comp = subprocess.run(command, shell=True, capture_output=True)\n",
    "        if comp.returncode != 0:\n",
    "            print(comp)\n",
    "    return comp.returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_duplex_color_tag(fin, fout):\n",
    "    if fin[-4:] == '.sam':\n",
    "        aln_in = pysam.AlignmentFile(fin, 'r')\n",
    "        aln_out = pysam.AlignmentFile(fout, 'w', template=aln_in)\n",
    "    elif fin[-4:] == '.bam':\n",
    "        aln_in = pysam.AlignmentFile(fin, 'rb')\n",
    "        aln_out = pysam.AlignmentFile(fout, 'wb', template=aln_in)\n",
    "    else:\n",
    "        print('ERROR: unknown file type')\n",
    "    \n",
    "    for read in aln_in.fetch():\n",
    "        frag_start = min(read.reference_start, read.next_reference_start)\n",
    "        frag_len = abs(read.template_length)\n",
    "        if read.has_tag('RX'):\n",
    "            frag_umi = read.get_tag('RX')\n",
    "        elif read.has_tag('RG'):\n",
    "            frag_umi = read.get_tag('RG')\n",
    "        else:\n",
    "            frag_umi = ''\n",
    "        read.set_tag('co', f'{frag_start}_{frag_len}_{frag_umi}')\n",
    "        aln_out.write(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses SAMtools to pick out alignment file reads around positions listed in a dataframe\n",
    "# df must contain a column named chom and pos\n",
    "# files is a list of sorted, indexed BAM file names\n",
    "# window_size: will output reads within window_size bp of each variant\n",
    "# run: if false, will print commands rather than running them\n",
    "# max_reads: max number of reads to \n",
    "def sam_view_df(df, files, outdir='data/align/views/', window_size=100, run=True, max_reads=5000, color=True):\n",
    "    positions = list(set(zip(df.chrom, df.pos))) # store positions as (chrom, pos) and drop duplicates\n",
    "    positions.sort(key=lambda x: x[1]) # sort by position\n",
    "    positions.sort(key=lambda x: x[0]) # sort by chromosome, this results in proper genome position order\n",
    "    \n",
    "    # group positions that are withing 2 * window_size from each other\n",
    "    last_pos = ('asdfasdf', -100000)\n",
    "    groups = [] \n",
    "    for pos in positions:\n",
    "        if pos[0] == last_pos[0] and pos[1] - last_pos[1] <= 2 * window_size: # if positions are too close\n",
    "            groups[-1].append(pos)\n",
    "        else:\n",
    "            groups.append([pos])\n",
    "        last_pos = pos\n",
    "    \n",
    "    # convert groups of positions into windows for viewing\n",
    "    windows = [] # (chrom, start, end)\n",
    "    for group in groups:\n",
    "        windows.append((group[0][0], max(0, group[0][1] - window_size), group[-1][1] + window_size))\n",
    "    \n",
    "    # generate and run/print samtools view and sort commands\n",
    "    folder = files[0].rsplit('/', 1)[0]\n",
    "    commands_list = []\n",
    "    tmp_files = [f'sam_view_df_tmp_{window[0]}_{window[1]}_{window[2]}.sam' for window in windows]\n",
    "    for file in files:\n",
    "        commands = []\n",
    "        for i, window in enumerate(windows):\n",
    "            commands.append(f'samtools view {file} {window[0]}:{window[1]}-{window[2]} | head -n {max_reads} > {tmp_files[i]}')\n",
    "        commands.append(f'samtools view -H {file} > sam_view_df_tmp_header.sam')\n",
    "        commands.append(f'cat sam_view_df_tmp_header.sam {\" \".join(tmp_files)} | samtools sort -o {outdir}view_{file.rsplit(\"/\", 1)[-1].rsplit(\".\", 1)[0]}.sam')\n",
    "        commands_list.append(commands)\n",
    "    if run:\n",
    "        for command_list in commands_list:\n",
    "            for command in command_list:\n",
    "                # print('Running: ' + command)\n",
    "                comp = subprocess.run(command, shell=True, capture_output=True)\n",
    "                if comp.returncode != 0:\n",
    "                    print(comp)\n",
    "        comp = subprocess.run(f'rm {\" \".join(tmp_files)} sam_view_df_tmp_header.sam', shell=True, capture_output=True)\n",
    "        if comp.returncode != 0:\n",
    "            print(comp)\n",
    "        \n",
    "        if color:\n",
    "            for file in files:\n",
    "                add_duplex_color_tag(f'{outdir}view_{file.rsplit(\"/\", 1)[-1].rsplit(\".\", 1)[0]}.sam', 'tmp.sam')\n",
    "                subprocess.run(f'mv tmp.sam {outdir}view_{file.rsplit(\"/\", 1)[-1].rsplit(\".\", 1)[0]}.sam', shell=True, capture_output=True)\n",
    "    else:\n",
    "        for commands in commands_list:\n",
    "            print(' &\\n'.join(commands[:-1]))\n",
    "            print('wait')\n",
    "            print(commands[-1])\n",
    "        print(f'rm {\" \".join(tmp_files)} sam_view_df_tmp_header.sam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterable for streaming multiple bam files in position sorted order, functionally the same as reading a file generated by samtools merge\n",
    "class BamStreamer:\n",
    "    aln_files = []\n",
    "    streams = []\n",
    "    cur_reads = []\n",
    "    read_starts = []\n",
    "    def __init__(self, bam_files, chrom):\n",
    "        self.aln_files = [pysam.AlignmentFile(f, 'rb') for f in bam_files]\n",
    "        self.streams = [self.aln_files[i].fetch(contig=chrom) for i in range(len(bam_files))]\n",
    "        self.cur_reads = [next(s) for s in self.streams]\n",
    "        self.read_starts = [r.reference_start for r in self.cur_reads]\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        min_idx = min(range(len(self.read_starts)), key=self.read_starts.__getitem__)\n",
    "        to_return = self.cur_reads[min_idx]\n",
    "        self.cur_reads[min_idx] = next(self.streams[min_idx])\n",
    "        self.read_starts[min_idx] = self.cur_reads[min_idx].reference_start\n",
    "        return min_idx, to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rainbow order: green, \n",
    "# the colors at index 9 and 10 \n",
    "__base_colors = ['#08843E', '#6ABD45', '#CEC82B', '#FDB714', '#F6891F', '#D55127', '#CE2127', '#C61E6F', '#A63493', '#6D3A96', '#4C479D', '#3960AD', '#1B99D5', '#29AD95', '#8F5423']\n",
    "__dark_colors = ['#09542B', '#508D40', '#9D9936', '#CB942B', '#C56F29', '#A54023', '#9F2428', '#961D55', '#762468', '#4E2667', '#34326D', '#28467D', '#005C99', '#1F7D6C', '#5F3819']\n",
    "__light_colors = ['#7CC57C', '#9ECC42', '#FAEE3B', '#FDCE57', '#F5A04E', '#F06941', '#F04D60', '#E05CA2', '#B86DAD', '#8866AC', '#696AB1', '#5D80C1', '#76B3E2', '#7ECCBF', '#BA795E']\n",
    "\n",
    "# the colors at index 2&3 (yellow-green and goldenrod), 5&6 (dark orange and red) and 9&10 (dark purple and dark blue) may be indistinguishable for certain types of colorblindness, \n",
    "# thus, excluding the last 3 colors makes the colormap more colorblind friendly\n",
    "# the red and brown may also be difficult to distinguish for red-blind protanopia, but it depended on the simulation\n",
    "\n",
    "__reorder = [0, 1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14]\n",
    "\n",
    "base_cmap = [__base_colors[i] for i in __reorder]\n",
    "dark_cmap = [__dark_colors[i] for i in __reorder]\n",
    "light_cmap = [__light_colors[i] for i in __reorder]\n",
    "\n",
    "full_cmap = []\n",
    "for i in __reorder:\n",
    "    full_cmap.append(__dark_colors[i])\n",
    "    full_cmap.append(__base_colors[i])\n",
    "    full_cmap.append(__light_colors[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# %matplotlib inline\n",
    "# fig, ax = matplotlib.pyplot.subplots()\n",
    "# for i, color in enumerate(base_cmap):\n",
    "#     ax.add_patch(matplotlib.patches.Rectangle((0 + i, 0), 1, 1, color=color))\n",
    "# for i, color in enumerate(dark_cmap):\n",
    "#     ax.add_patch(matplotlib.patches.Rectangle((0 + i, 1), 1, 1, color=color))\n",
    "# for i, color in enumerate(light_cmap):\n",
    "#     ax.add_patch(matplotlib.patches.Rectangle((0 + i, -1), 1, 1, color=color))\n",
    "# ax.set_xlim(0, len(base_cmap))\n",
    "# ax.set_ylim(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatter to pass argparse formatter_class which \n",
    "import argparse\n",
    "class EscapeFormatter(argparse.HelpFormatter):\n",
    "    def _fill_text(self, text, width, indent):\n",
    "        text = self._whitespace_matcher.sub(' ', text).strip()\n",
    "        paragraphs = text.split('|n ')\n",
    "        import textwrap\n",
    "        multiline_text = ''\n",
    "        for paragraph in paragraphs:\n",
    "            formatted_paragraph = textwrap.fill(paragraph.replace('|t', '\\t'), width, initial_indent=indent, subsequent_indent=indent) + '\\n'\n",
    "            multiline_text += formatted_paragraph\n",
    "        return multiline_text \n",
    "    # def _fill_text(self, text, width, indent):\n",
    "    #     text = self._whitespace_matcher.sub(' ', text).strip()\n",
    "    #     import textwrap\n",
    "    #     return textwrap.fill(text, width,\n",
    "    #                          initial_indent=indent,\n",
    "    #                          subsequent_indent=indent).replace('|n', '\\n').replace('|t', '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
