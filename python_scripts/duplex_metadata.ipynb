{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gtools\n",
    "import pysam\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.colors as colors\n",
    "import multiprocessing\n",
    "import pickle\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "import itertools\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='''\n",
    "Outputs metadata statistics and figures on a list of NanoSeq BAM files. NOTE: it is highly recommended to set --region|n\n",
    "|n\n",
    "Outputs {prefix}metadata.tsv with columns:|n\n",
    "- sample: name of BAM file|n\n",
    "- rep: name of replicate extracted from the UMI tag (optional)|n\n",
    "- sample_read_pairs_whole_genome: total number of concordant read pairs in the sample. All other statistics are for only the region specified with --region|n\n",
    "- sample_conflict_rate: the estimated fraction of fragments in the sample which will not be callable due to another fragment at the same alignment position \n",
    "with sufficient reads|n\n",
    "- rep_read_pairs: concordant read pairs in the replicate (in --region)|n\n",
    "- rep_frags: number of fragments in the replicate (in --region)|n\n",
    "- rep_frags_both_strands: number of fragments in the replicate (in --region) with both strands sequenced |n\n",
    "- rep_frags_call_overlap: number of fragments in the replicate (in --region) with enough coverage to call in the read1-read2 overlap (>=B/2 read pairs per \n",
    "strand and >=C/2 read pairs total)|n\n",
    "- rep_frags_call_whole: number of fragments in the replicate (in --region) with enough coverage to call the whole fragment (>=B read pairs per strand and \n",
    ">=C read pairs total)|n\n",
    "|n\n",
    "Outputs the following figures:|n\n",
    "- {prefix}conflict_rates.svg: scatterplot showing the relationship between fragment count and conflict rate as well as the line used to impute conflict \n",
    "rate for samples with one replicate|n\n",
    "- {prefix}subsampling_efficiency.svg: used to estimate dilution efficiency. Replicates libraries have their reads subsampled to various levels and sequencing\n",
    "efficiency (callable fragments / aligned read pair) is calculated for each level. An optimally diluted library will plateau at 1, while an oversequenced library\n",
    "will peak at a subsample level < 1. Note: callable fragments here does not take into account mapping quality or blacklists.|n\n",
    "- {prefix}reads_per_molecule.svg: histogram of the number of reads per molecule.|n\n",
    "|n\n",
    "Lastly, a dictionary of the conflict rates is written to stdout for copying into the duplex_mutation_figures notebook.\n",
    "    ''', formatter_class=gtools.EscapeFormatter)\n",
    "parser.add_argument('-i', '--input', dest='input', metavar='BAM', type=str, nargs='+', required=True,\n",
    "                   help='input BAM files of duplex-seq libraries')\n",
    "parser.add_argument('-o', '--output', dest='output', metavar='PREFIX', type=str, required=True,\n",
    "                   help='prefix to prepend the output metadata table and figures')\n",
    "parser.add_argument('-u', '--umi', dest='umi', metavar='TAG', type=str,\n",
    "                   help='BAM tag containing the UMI (default: no UMI)')\n",
    "parser.add_argument('-r', '--replicate', dest='replicate', metavar='SEPARATOR,INDEX', type=str,\n",
    "                   help='should be set if a single BAM file contains multiple replicate samples. These replicates will be \\\n",
    "                   treated separately in the metadata output and are necessary for calculating an estimated conflict \\\n",
    "                   rate for a BAM file. The replicate name is extracted from the UMI tag by splitting \\\n",
    "                   on SEPARATOR and taking the substring at INDEX. e.g. with \"--umi RX --sample_extract _,1\", \\\n",
    "                   an RX tag of \"CACGTC_library1\" will extract \"library1\" as the replicate name. Pass an \\\n",
    "                   empty SEPARATOR to indicate that the UMI is the replicate name (default: treat each \\\n",
    "                   BAM as one replicate)')\n",
    "parser.add_argument('-g', '--region', dest='region', metavar='CHROM:START-END', type=str,\n",
    "                   help='consider only reads with start positions within this region. Significantly reduces runtime \\\n",
    "                   (default: use whole genome)')\n",
    "parser.add_argument('-s', '--subsample_levels', dest='sub_levels', metavar='FLOAT', type=float, nargs='+', default=[0.2, 0.4, 0.6, 0.8, 1],\n",
    "                   help='subsample the library to these fractions of reads when visualizing dilution efficiency \\\n",
    "                   (default: 0.2 0.4 0.6 0.8 1)')\n",
    "parser.add_argument('-B', '--min_strand_cov', dest='min_strand_cov', metavar='INT', type=int, default=2,\n",
    "                   help='filter cutoff for calling variants, used for determining fragments with enough coverage to call: \\\n",
    "                   minimum reads per strand overlapping variant (default: 2)')\n",
    "parser.add_argument('-C', '--min_total_cov', dest='min_total_cov', metavar='INT', type=int, default=6,\n",
    "                   help='filter cutoff for calling variants, used for determining fragments with enough coverage to call: \\\n",
    "                   minimum total reads overalpping variant (default: 6)')\n",
    "parser.add_argument('-N', '--min_frac_final', dest='min_frac_final', metavar='FLOAT', type=float, default=0.76,\n",
    "                   help='filter cutoff for calling variants, used in calculating conflict rate: final minimum fraction \\\n",
    "                   of supporting reads per strand (default: 0.76)')\n",
    "parser.add_argument('-@', '--threads', dest='threads', metavar='INT', type=int, default=1,\n",
    "                   help='multiprocessing threads for parallel processing of BAM files (default: 1)')\n",
    "parser.add_argument('--tmp', dest='tmp', metavar='PREFIX', type=str, default='tmp/',\n",
    "                   help='prefix for temporary files (default: ./)')\n",
    "\n",
    "try: # run this if in a jupyter notebook\n",
    "    get_ipython()\n",
    "    print('Determined code is running in Jupyter')\n",
    "    if os.getcwd()[:8] != '/scratch': # switch to the scratch directory where all the data files are\n",
    "        os.chdir(f'/scratch/cam02551/{os.getcwd().split(\"/\")[-2]}')\n",
    "    args = parser.parse_args('-i data/align/big_Col-0-1_merged.bam data/align/big_Col-0-2_merged.bam -o tmp/metadata_test_ -g Chr1:0-100000 -u RG -r ,0 --tmp tmp/'.split()) # used for testing\n",
    "except: # run this if in a terminal\n",
    "    args = parser.parse_args()\n",
    "\n",
    "sys.stderr.write('Running duplex_metadata.py with arguments:\\n' + '\\n'.join([f'{key}={val}' for key, val in vars(args).items()]) + '\\n')\n",
    "\n",
    "if args.output and '/' in args.output:\n",
    "    os.makedirs(os.path.dirname(args.output), exist_ok=True)\n",
    "if '/' in args.tmp:\n",
    "    os.makedirs(os.path.dirname(args.tmp), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname('asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.region:\n",
    "    contig = args.region.split(':')[0]\n",
    "    pos_start = int(args.region.split(':')[1].split('-')[0])\n",
    "    pos_end = int(args.region.split('-')[1])\n",
    "\n",
    "if args.replicate:\n",
    "    if not args.umi:\n",
    "        sys.stderr.write('ERROR: must specificy --umi if specifying --replicate')\n",
    "        sys.exit()\n",
    "    rep_sep = args.replicate.split(',')[0]\n",
    "    rep_index = int(args.replicate.split(',')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Extract fragment information from the BAM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pickled dictionary with key=replicate value=[(chrom, start, tlen, umi, + strand pairs, - strand pairs)]\n",
    "def get_frags(file, out, pbar_i, sub=2):\n",
    "    aln = pysam.AlignmentFile(file, 'rb')\n",
    "    total_reads = sum([x.total for x in aln.get_index_statistics()])\n",
    "    genome_size = sum([aln.get_reference_length(x.contig) for x in aln.get_index_statistics()])\n",
    "    pbar_total = int((pos_end - pos_start) / genome_size * total_reads) if args.region else total_reads\n",
    "    fetch_iter = aln.fetch(contig=contig, start=pos_start, end=pos_end) if args.region else aln.fetch()\n",
    "    \n",
    "    fragments = defaultdict(lambda: [0, 0])\n",
    "    rep_reads = defaultdict(lambda: 0)\n",
    "    for read in tqdm(fetch_iter, position=pbar_i, total=pbar_total, miniters=200000, maxinterval=999):\n",
    "        frag_start = read.reference_start\n",
    "        tlen = abs(read.template_length) # this is non-inclusive\n",
    "        if args.umi:\n",
    "            umi = read.get_tag(args.umi)\n",
    "        else:\n",
    "            umi = ''\n",
    "        if args.replicate:\n",
    "            rep = umi.split(rep_sep)[rep_index] if len(rep_sep) > 0 else umi\n",
    "        else:\n",
    "            rep = ''\n",
    "        \n",
    "        rep_reads[rep] += 1\n",
    "        \n",
    "        # thow out read pairs that don't align as expected, ignore read 2 so we don't double count pairs\n",
    "        if read.is_unmapped or read.mate_is_unmapped or not (read.flag & 2) or read.is_reverse or read.mapping_quality < 10:\n",
    "            continue\n",
    "        \n",
    "        if random.random() > sub:\n",
    "            continue\n",
    "        \n",
    "        frag_strand = '+' if read.is_read1 else '-'\n",
    "        \n",
    "        if frag_strand == '+':\n",
    "            fragments[(read.reference_name, frag_start, tlen, umi, rep)][0] += 1\n",
    "        else:\n",
    "            fragments[(read.reference_name, frag_start, tlen, umi, rep)][1] += 1\n",
    "                \n",
    "    fragments = dict(fragments)\n",
    "    frags = {rep:[] for rep in sorted(rep_reads)}\n",
    "    for frag in fragments:\n",
    "        frags[frag[4]].append((frag[0], frag[1], frag[2], frag[3], fragments[frag][0], fragments[frag][1]))\n",
    "    \n",
    "    with open(out, 'wb') as fout:\n",
    "        pickle.dump(frags, fout)\n",
    "\n",
    "    aln.close()\n",
    "    \n",
    "    # tqdm.write(f'{os.path.basename(file)}: {sum(rep_reads.values())} reads{\" in \" + args.region if args.region else \"\"}', file=sys.stdout)\n",
    "    # for rep in rep_reads:\n",
    "    #     tqdm.write(f'\\treplicate {rep}: {rep_reads[rep]} reads{\" in \" + args.region if args.region else \"\"}', file=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    tqdm.write('counting reads and fragments in BAM files\\n', file=sys.stderr)\n",
    "    pool = multiprocessing.Pool(processes=8)\n",
    "    processes = []\n",
    "    for i, f in enumerate(args.input):\n",
    "        processes.append(pool.apply_async(get_frags, (f, f'{args.tmp}duplex_metadata_{os.path.basename(f)}_frags.pkl', i)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    # check for errors\n",
    "    for p in processes:\n",
    "        p.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.write('loading temporary fragment files\\n', file=sys.stderr)\n",
    "frags = dict() # key: sample; value: [(chrom, frag_start, tlen, umi, + reads, - reads)]\n",
    "for file_name in tqdm(args.input, position=0):\n",
    "    with open(f'{args.tmp}duplex_metadata_{os.path.basename(file_name)}_frags.pkl', 'rb') as f:\n",
    "        l = pickle.load(f)\n",
    "        frags[os.path.basename(file_name)] = l\n",
    "    os.remove(f'{args.tmp}duplex_metadata_{os.path.basename(file_name)}_frags.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Plot reads per fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot total coverage of each fragment to estimate the number of viable fragments in the library\n",
    "fig, axs = plt.subplots(sum([len(frags[s]) for s in frags]), figsize=(4, 0.5 * sum([len(frags[s]) for s in frags])), sharex=True)\n",
    "axs = [axs] if sum([len(frags[s]) for s in frags]) == 1 else axs # convert axs to a list if only one subplot\n",
    "i = 0\n",
    "for sample in tqdm(frags):\n",
    "    for rep in frags[sample]:\n",
    "        axs[i].hist([x[4] + x[5] for x in frags[sample][rep]], bins=range(30))\n",
    "        axs[i].hist([x[4] + x[5] for x in frags[sample][rep] if x[4] > 0 and x[5] > 0], bins=range(30))\n",
    "        axs[i].set_title(f'{sample} {rep}', x=0.98, y=0.4, ha='right', size=8)\n",
    "        i += 1\n",
    "axs[-1].set_xlabel('# read pairs covering fragment')\n",
    "axs[len(axs) // 2].set_ylabel('# molecules')\n",
    "axs[0].legend(['Reads in 1 strand', 'Reads in both strands'], loc='lower center', bbox_to_anchor=(0.5, 1))\n",
    "fig.suptitle('Read coverage per molecule', y=0.94)\n",
    "fig.savefig(f'{args.output}reads_per_molecule.svg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Calculate conflict rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.write('calculating conflict rates\\n', file=sys.stderr)\n",
    "conflict_rates = dict()\n",
    "for i, sample in tqdm(enumerate(frags), total=len(frags), position=0):\n",
    "    \n",
    "    # for each replicate, randomly sample half as many fragments from other replicates to compute a \"half\" conflict rate \n",
    "    # (the true conflict rate is calculated as 1 - (1-half conflict rate)^2)\n",
    "    # the reason I calculate a \"half\" rate is that some samples only have 2 replicates, and if one has more fragments than the other, its \n",
    "    # \"full\" conflict rate can't be calculated, so I use the half as a close approximation\n",
    "    rates = []\n",
    "    rep_frag_counts = []\n",
    "    if len(frags[sample]) == 1:\n",
    "        conflict_rates[sample] = 0\n",
    "        continue\n",
    "    \n",
    "    for rep in frags[sample]:\n",
    "        rep_frags = frags[sample][rep] # fragments from this rep\n",
    "        other_frags = list(itertools.chain.from_iterable([frags[sample][r] for r in frags[sample] if r != rep])) # fragments from other reps\n",
    "        \n",
    "        # randomly select half as many fragments from other_frags as are in rep_frags\n",
    "        ratio = len(rep_frags) / len(other_frags)\n",
    "        if ratio > 2:\n",
    "            continue\n",
    "        other_subsample = {(x[0], x[1], x[2]):(x[4], x[5]) for x in other_frags if random.random() < 0.5 * ratio}\n",
    "        \n",
    "        # count the number of conflicts which make a fragment uncallable\n",
    "        uncallable_conflicts = 0\n",
    "        for frag in rep_frags:\n",
    "            if (frag[0], frag[1], frag[2]) in other_subsample: # if there's a conflict\n",
    "                # if the fragment doesn't contribute at least 76% of the top and bottom strand pairs, the conflict will be uncallable\n",
    "                if frag[4] / max(1, (frag[4] + other_subsample[(frag[0], frag[1], frag[2])][0])) < args.min_frac_final or \\\n",
    "                   frag[5] / max(1, (frag[5] + other_subsample[(frag[0], frag[1], frag[2])][1])) < args.min_frac_final:\n",
    "                    uncallable_conflicts += 1\n",
    "        conflict_rate = 1 - (1 - (uncallable_conflicts / len(rep_frags))) ** 2\n",
    "        rates.append(conflict_rate)\n",
    "        \n",
    "        rep_frag_counts.append(sum([x[4] > 0 and x[5] > 0 for x in rep_frags])) # estimated number of callable fragments\n",
    "    \n",
    "    # calculate the sample conflict rate as the average across replicates, weighted by the number of fragments in the replicate\n",
    "    conflict_rates[sample] = sum([rates[i] * rep_frag_counts[i] / sum(rep_frag_counts) for i in range(len(rates))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a best fit correlation between fragment number and conflict rate (only use samples where conflict rate could be estimated)\n",
    "counts = []\n",
    "rates = []\n",
    "for sample in frags:\n",
    "    if conflict_rates[sample] == 0:\n",
    "        continue\n",
    "    counts.append(sum([len(frags[sample][r]) for r in frags[sample]]))\n",
    "    rates.append(conflict_rates[sample])\n",
    "counts += [0] * 10000 # my tiny brain can't figure out how to fix the intercept at 0, so I'm just adding a bunch of points at (0, 0)\n",
    "rates += [0] * 10000\n",
    "slope, intercept = np.polyfit(counts, rates, 1) if len(counts) > 10000 else (0, 0)\n",
    "line_x = np.linspace(0, 5000000, 1000)\n",
    "line_y = [x * slope + intercept for x in line_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_rates = conflict_rates.copy()\n",
    "for sample in imputed_rates:\n",
    "    if imputed_rates[sample] == 0:\n",
    "        imputed_rates[sample] = sum([len(frags[sample][r]) for r in frags[sample]]) * slope + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter([sum([len(frags[s][r]) for r in frags[s]]) for s in imputed_rates], imputed_rates.values(), color=['tab:blue' if conflict_rates[s] == 0 else 'tab:orange' for s in imputed_rates])\n",
    "xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "ax.plot(line_x, line_y)\n",
    "ax.set_xlim(xlim), ax.set_ylim(ylim)\n",
    "ax.set_xlabel(f'Fragment number in {args.region}' if args.region else 'Fragment number')\n",
    "ax.set_ylabel('Conflict rate')\n",
    "ax.set_title('Conflict rate and fragment number')\n",
    "s_blue = plt.scatter([], [], c='tab:blue')\n",
    "s_orange = plt.scatter([], [], c='tab:orange')\n",
    "ax.legend([s_orange, s_blue], ['calculated', 'imputed'])\n",
    "fig.savefig(f'{args.output}conflict_rate.svg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.write('conflict rates:\\n', file=sys.stdout)\n",
    "tqdm.write(str(imputed_rates), file=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Create metadata tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.write('writing metadata tsv\\n', file=sys.stderr)\n",
    "metadata = []\n",
    "for f in args.input:\n",
    "    sample = os.path.basename(f)\n",
    "    aln = pysam.AlignmentFile(f, 'rb')\n",
    "    sample_pairs = sum([x.total for x in aln.get_index_statistics()]) // 2\n",
    "    aln.close()\n",
    "    for rep in frags[sample]:\n",
    "        rep_pairs = sum([x[4] + x[5] for x in frags[sample][rep]])\n",
    "        rep_frags = len(frags[sample][rep])\n",
    "        rep_both_strands = sum([x[4] > 0 and x[5] > 0 for x in frags[sample][rep]])\n",
    "        rep_call_overlap = sum([x[4] >= args.min_strand_cov // 2 and x[5] >= args.min_strand_cov // 2 and x[4] + x[5] >= args.min_total_cov // 2 for x in frags[sample][rep]])\n",
    "        rep_call_whole = sum([x[4] >= args.min_strand_cov and x[5] >= args.min_strand_cov and x[4] + x[5] >= args.min_total_cov for x in frags[sample][rep]])\n",
    "        metadata.append((sample, rep, sample_pairs, imputed_rates[sample], rep_pairs, rep_frags, rep_both_strands, rep_call_overlap, rep_call_whole))\n",
    "df_meta = pd.DataFrame(metadata, columns='sample rep sample_read_pairs_whole_genome sample_conflict_rate rep_read_pairs rep_frags rep_frags_both_strands rep_frags_call_overlap rep_frags_call_whole'.split())\n",
    "df_meta.to_csv(f'{args.output}metadata.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Subsample to determine sequencing efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_levels = sorted(args.sub_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    tqdm.write('counting reads and fragments while subsampling BAM files\\n', file=sys.stderr)\n",
    "    pool = multiprocessing.Pool(processes=8)\n",
    "    processes = []\n",
    "    for i, f in enumerate(args.input):\n",
    "        for j, sub_level in enumerate(sub_levels):\n",
    "            processes.append(pool.apply_async(get_frags, (f, f'{args.tmp}duplex_metadata_{os.path.basename(f)}_{sub_level}_frags.pkl', i * len(args.input) + j, sub_level)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # check for errors\n",
    "    for p in processes:\n",
    "        p.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.write('loading temporary subsampled fragment files\\n', file=sys.stderr)\n",
    "sub_frags = defaultdict(lambda: dict())\n",
    "for i, file_name in tqdm(enumerate(args.input)):\n",
    "    for sub_level in sub_levels:\n",
    "        with open(f'{args.tmp}duplex_metadata_{os.path.basename(file_name)}_{sub_level}_frags.pkl', 'rb') as f:\n",
    "            frags = pickle.load(f)\n",
    "            for replicate in sorted(list(frags.keys())):\n",
    "                sub_frags[os.path.basename(file_name) + ' ' + replicate][sub_level] = frags[replicate]\n",
    "        os.remove(f'{args.tmp}duplex_metadata_{os.path.basename(file_name)}_{sub_level}_frags.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_frags = {x:sub_frags[x] for x in list(sub_frags)}\n",
    "\n",
    "cmap = plt.cm.tab20\n",
    "fig, axs = plt.subplots(3, figsize=(len(subset_frags), 6), sharex=True, sharey=True)\n",
    "for i, req_strand, req_total in zip(range(3), [1, 1, 2], [2, 3, 4]):\n",
    "    seq_eff_overlap = []\n",
    "    seq_eff_all = []\n",
    "    for sample in subset_frags:\n",
    "        for sub_level in sub_levels:\n",
    "            total_reads = sum([x[4] + x[5] for x in subset_frags[sample][sub_level]])\n",
    "            callable_frags_overlap = len([x for x in subset_frags[sample][sub_level] if x[4] >= req_strand and x[5] >= req_strand and x[4] + x[5] >= req_total])\n",
    "            callable_frags_all = len([x for x in subset_frags[sample][sub_level] if x[4] >= 2 * req_strand and x[5] >= 2 * req_strand and x[4] + x[5] >= 2 * req_total])\n",
    "            seq_eff_overlap.append(callable_frags_overlap / total_reads)\n",
    "            seq_eff_all.append(callable_frags_all / total_reads)\n",
    "    axs[i].bar(range(len(seq_eff_overlap)), seq_eff_overlap, color=[cmap((x // len(sub_levels)) % 2) for x in range(len(seq_eff_overlap))])\n",
    "    axs[i].bar(range(len(seq_eff_all)), seq_eff_all, color=[cmap((x // len(sub_levels)) % 2 + 2) for x in range(len(seq_eff_all))])\n",
    "    axs[i].set_title(f'Need >={req_strand * 2} reads per strand and >={req_total * 2} total to call', y=0.7)\n",
    "axs[1].set_ylabel('Callable fragmens per concordant read pair')\n",
    "axs[-1].set_xticks([len(sub_levels) // 2 + x * len(sub_levels) for x in range(len(subset_frags))])\n",
    "axs[-1].set_xticklabels(subset_frags.keys(), rotation=45, ha='right')\n",
    "axs[0].legend(['only read1/2 overlap is callable', 'all of fragment is callable'], bbox_to_anchor=(1, 1), loc='upper left')\n",
    "blank = plt.Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
    "axs[1].legend([blank] * 2, ['subsample levels:', ', '.join(map(str, sub_levels))] + sub_levels, bbox_to_anchor=(1, 1), loc='upper left')\n",
    "fig.suptitle('Dilution efficiency of subsampled libraries', y=0.95)\n",
    "fig.savefig(f'{args.output}subsampling_efficiency.svg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.write(f'completed duplex_metadata.py on {args.input}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
