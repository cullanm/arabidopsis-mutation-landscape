{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import subprocess\n",
    "from multiprocessing import Process\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import argparse\n",
    "import gtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='''\n",
    "Makes a randomly strand-swapped NanoSeq library from several input NanoSeq libraries. For each fragment start and end position in the input libraries, one\n",
    "set of top strand PCR duplicates (F1R2) and one set of bottom strand PCR duplicates (F2R1) is randomly selected from two different samples. If this isn't \n",
    "possible, nothing is output for that fragment. Each BAM input must have a RG tag which identifies the sample a read came from after removing \n",
    "--replicate_chars characters from the end of the RG. Note: if the input reads had a umi in the tags, it will not be overwritten, so don't set --umi when \n",
    "running duplex_caller on the output.|n\n",
    "|n\n",
    "The point of this script is to make all the true mutations uncallable, while keeping the false positive rate the same. Because FPs appear in strands \n",
    "independently, it shouldn't matter how we rearrange the strands, the likelihood of pairing two strands with the same FP remains the same. |n\n",
    "|n\n",
    "Example:|n \n",
    "For one fragment start and end position, three samples have read from both the top and bottom strand. We randomly choose sample_3 to contribute the top strand\n",
    "reads, then we randomly chose sample_1 from the remaining samples to contribute the bottom strand reads (we don't allow chosing the same sample for both). For \n",
    "this fragment, only sample_3 top strand and sample_1 bottom strand reads are output.\n",
    "    ''', formatter_class=gtools.EscapeFormatter)\n",
    "parser.add_argument('-i', '--input', required=True, dest='input', metavar='FILES', type=str, nargs='+',\n",
    "                   help='input NanoSeq BAM files. Must be coordinate sorted and indexed')\n",
    "parser.add_argument('-o', '--output', required=True, dest='output', metavar='FILE', type=str,\n",
    "                   help='output strand-swapped BAM file')\n",
    "parser.add_argument('-u', '--umi', dest='umi', metavar='TAG', type=str, default=None,\n",
    "                   help='name of tag which contains the fragment umi')\n",
    "parser.add_argument('-t', '--tmp', dest='tmp_prefix', metavar='PREFIX', type=str, default='tmp/',\n",
    "                   help='prefix to add to temporary files. Will make any directories which do not exist (default: tmp/)')\n",
    "parser.add_argument('-@', '--threads', dest='threads', metavar='INT', type=int, default=1,\n",
    "                   help='number of threads. Each chromosome can be processed by a separate thread. (default: 1)')\n",
    "\n",
    "try: # run this if in a jupyter notebook\n",
    "    get_ipython()\n",
    "    print('Determined code is running in Jupyter')\n",
    "    args = parser.parse_args('-@ 8 --umi RG -o tmp/swapper_test.bam -i data/align/big_Col-0-1_merged.bam data/align/big_Col-0-2_merged.bam data/align/big_Col-0-3_merged.bam'.split()) # used for testing\n",
    "except: # run this if in a terminal\n",
    "    args = parser.parse_args()\n",
    "\n",
    "sys.stderr.write('Running duplex_strand_swapper.py with arguments:\\n' + '\\n'.join([f'{key}={val}' for key, val in vars(args).items()]) + '\\n')\n",
    "if args.tmp_prefix and '/' in args.tmp_prefix:\n",
    "    os.makedirs(os.path.dirname(args.tmp_prefix), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterable for streaming multiple bam files in position sorted order, functionally the same as reading a file generated by samtools merge\n",
    "class BamStreamer:\n",
    "    aln_files = []\n",
    "    streams = []\n",
    "    cur_reads = []\n",
    "    read_starts = []\n",
    "    def __init__(self, bam_files, chrom):\n",
    "        self.aln_files = [pysam.AlignmentFile(f, 'rb') for f in bam_files]\n",
    "        self.streams = [self.aln_files[i].fetch(contig=chrom) for i in range(len(bam_files))]\n",
    "        self.cur_reads = [next(s) for s in self.streams]\n",
    "        self.read_starts = [r.reference_start for r in self.cur_reads]\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        min_idx = min(range(len(self.read_starts)), key=self.read_starts.__getitem__)\n",
    "        to_return = self.cur_reads[min_idx]\n",
    "        self.cur_reads[min_idx] = next(self.streams[min_idx])\n",
    "        self.read_starts[min_idx] = self.cur_reads[min_idx].reference_start\n",
    "        return to_return\n",
    "    def close(self):\n",
    "        for f in self.aln_files:\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_interval = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strand_swap(output_file, chrom):\n",
    "    stream_in = BamStreamer(args.input, chrom) # iterator over reads in multiple files\n",
    "    aln_out = pysam.AlignmentFile(output_file, 'wb', template=stream_in.aln_files[0])\n",
    "    cur_source, cur_read = next(stream_in)\n",
    "    reverse_to_output = dict() # whenever a forward read is output, add an item of query name:new RG tag\n",
    "    done = False\n",
    "    next_update = update_interval\n",
    "    while not done:\n",
    "        cur_pos = cur_read.reference_start\n",
    "        \n",
    "        # get all the reads with the same starting position\n",
    "        reads = defaultdict(lambda: []) # stores the forward reads, key=tlen, value=[(file source, read)]\n",
    "        reverse_reads = [] # stores the reverse reads\n",
    "        while cur_read.reference_start == cur_pos:\n",
    "            if cur_read.is_reverse:\n",
    "                reverse_reads.append(cur_read)\n",
    "            else:\n",
    "                reads[abs(cur_read.template_length)].append((cur_source, cur_read))\n",
    "            try:\n",
    "                cur_source, cur_read = next(stream_in)\n",
    "            except StopIteration:\n",
    "                done = True\n",
    "                break\n",
    "        \n",
    "        \n",
    "        for tlen in reads:\n",
    "            top_sources = list(set([(source, read.get_tag(args.umi)) for source, read in reads[tlen] if read.is_read1]))\n",
    "            bot_sources = list(set([(source, read.get_tag(args.umi)) for source, read in reads[tlen] if read.is_read2]))\n",
    "            \n",
    "            if len(top_sources) == 0:\n",
    "                continue\n",
    "                \n",
    "            top_sample = random.choice(top_sources)\n",
    "            bot_sources = [(source, umi) for source, umi in bot_sources if source != top_sample[0]]\n",
    "            \n",
    "            if len(bot_sources) == 0:\n",
    "                continue\n",
    "            \n",
    "            bot_sample = random.choice(bot_sources)\n",
    "            \n",
    "            for source, read in reads[tlen]:\n",
    "                if (read.is_read1 and source == top_sample[0] and read.get_tag(args.umi) == top_sample[1]) or \\\n",
    "                   (read.is_read2 and source == bot_sample[0] and read.get_tag(args.umi) == bot_sample[1]):\n",
    "                    read.set_tag(args.umi, f'{top_sample[0]}:{top_sample[1]}_{bot_sample[0]}:{bot_sample[1]}')\n",
    "                    aln_out.write(read)\n",
    "                    reverse_to_output[read.query_name] = f'{top_sample[0]}:{top_sample[1]}_{bot_sample[0]}:{bot_sample[1]}'\n",
    "\n",
    "        # output any reverse reads \n",
    "        for read in reverse_reads:\n",
    "            if read.query_name in reverse_to_output:\n",
    "                read.set_tag(args.umi, reverse_to_output[read.query_name])\n",
    "                aln_out.write(read)\n",
    "                del reverse_to_output[read.query_name]\n",
    "        \n",
    "        if cur_pos >= next_update:\n",
    "            sys.stderr.write(f'passed {chrom}:{next_update}\\n')\n",
    "            next_update += update_interval\n",
    "        \n",
    "    stream_in.close()\n",
    "    aln_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pysam.AlignmentFile(args.input[0], 'rb')\n",
    "chroms = a.references\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # start worker processes from pool\n",
    "    pool = multiprocessing.Pool(processes=args.threads)\n",
    "    processes = []\n",
    "    for chrom in chroms:\n",
    "        processes.append(pool.apply_async(strand_swap, (f'{args.tmp_prefix}{args.output.replace(\"/\", \".\")}_{chrom}.bam', chrom)))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # check for errors\n",
    "    for p in processes:\n",
    "        p.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cat = ' '.join([f'{args.tmp_prefix}{args.output.replace(\"/\", \".\")}_{chrom}.bam' for chrom in chroms])\n",
    "\n",
    "p = subprocess.run(f'samtools cat -@ {args.threads} -o {args.output} {to_cat}', shell=True, capture_output=True)\n",
    "if p.returncode != 0:\n",
    "    sys.stderr.write(p.stderr)\n",
    "    exit()\n",
    "    \n",
    "p = subprocess.run(f'rm {to_cat}', shell=True, capture_output=True)\n",
    "if p.returncode != 0:\n",
    "    sys.stderr.write(p.stderr)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.write(f'completed duplex_strand_swapper with output {args.output}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
